{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oUDO08wZabuA"
      },
      "source": [
        "Bomberman Env\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "m2zvNGqSZ-Tz"
      },
      "outputs": [],
      "source": [
        "import gym\n",
        "from gym import spaces\n",
        "import numpy as np\n",
        "import pygame\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "class Item(object):\n",
        "    def __init__(self,pos):\n",
        "        self.pos = pos\n",
        "\n",
        "class Box(Item):\n",
        "    def __init__(self,pos,breakable,broken,target):\n",
        "        super(Box,self).__init__(pos)\n",
        "        self.isBreakable = breakable\n",
        "        self.isTarget = target\n",
        "        self.isBroken = broken\n",
        "\n",
        "    def get_state(self):\n",
        "        return (self.pos, self.isBreakable, self.isTarget,self.isBroken)\n",
        "\n",
        "class Enemy(Item):\n",
        "    def __init__(self,pos,orientation,way,isAlive):\n",
        "        super(Enemy,self).__init__(pos)\n",
        "        self.orientation = orientation\n",
        "        self.way = way\n",
        "        self.isAlive = isAlive\n",
        "\n",
        "\n",
        "    def get_state(self):\n",
        "        return (self.pos, self.orientation, self.way, self.isAlive)\n",
        "\n",
        "\n",
        "\n",
        "class Bomb(Item):\n",
        "    def __init__(self,pos,timer):\n",
        "        super(Bomb,self).__init__(pos)\n",
        "        self.timer = timer\n",
        "\n",
        "    def get_state(self):\n",
        "        return (self.pos, self.timer)\n",
        "\n",
        "\n",
        "class Explosion(Item):\n",
        "    def __init__(self,pos):\n",
        "        super(Explosion,self).__init__(pos)\n",
        "\n",
        "    def get_state(self):\n",
        "        return (self.pos)\n",
        "\n",
        "def mult(x,y):\n",
        "        if(x > y):\n",
        "            multi = x/y\n",
        "        else:\n",
        "            multi = y/x\n",
        "        return multi\n",
        "\n",
        "def exist(list,pos):\n",
        "    for i in range(len(list)):\n",
        "        if(pos[0] == list[i].pos[0] and pos[1] == list[i].pos[1]):\n",
        "            return True\n",
        "    return False\n",
        "\n",
        "\n",
        "class BombermanEnv(gym.Env):\n",
        "    metadata = {\"render_modes\": [\"human\", \"rgb_array\"], \"render_fps\": 3}\n",
        "\n",
        "    def __init__(self, width, height, boxes, enemies_x, enemies_y, rompible_file, render_mode = None):\n",
        "        super(BombermanEnv, self).__init__()\n",
        "\n",
        "        self.width = width\n",
        "        self.height = height\n",
        "        if boxes < 1:\n",
        "            print(\"El numero de cajas debe ser mayor que 1.\")\n",
        "            return\n",
        "        self.list_boxes = [] # lista para las cajas rompibles e irrompibles\n",
        "        self.boxes = boxes # total de cajas rompibles\n",
        "        self.list_boxes_breakable = [] # lista para las cajas rompibles\n",
        "        self.list_enemies = [] # lista que contendra a los enemigos\n",
        "        self.enemies_x = enemies_x # total de enemigos horizontales\n",
        "        self.enemies_y = enemies_y # total de enemigos verticales\n",
        "        self.rompible_file = rompible_file # archivo de cajas irrompibles\n",
        "        self._agent_location = np.array([0,0])\n",
        "        self.active_bomb = 0\n",
        "        self.observation = self._get_obs()\n",
        "        m = mult(self.width, self.height)\n",
        "        if(self.width > self.height):\n",
        "            self.window_height = 670\n",
        "            self.window_width = m * self.window_height\n",
        "        else:\n",
        "            self.window_width = 512\n",
        "            self.window_height = m * self.window_width\n",
        "\n",
        "        # Define la forma del espacio de observación (en este caso, una imagen binaria)\n",
        "        self.observation_space = spaces.Box(low=0, high=1, shape=(len(self.observation),), dtype=np.float32)\n",
        "\n",
        "        # Define el espacio de acción (puedes personalizar esto según tu entorno)\n",
        "        self.action_space = spaces.Discrete(6)  # Ejemplo: acciones discretas 0, 1, 2, 3\n",
        "\n",
        "        self._action_to_direction = {\n",
        "            0: np.array([1, 0]),\n",
        "            1: np.array([0, 1]),\n",
        "            2: np.array([-1, 0]),\n",
        "            3: np.array([0, -1]),\n",
        "            4: np.array([0, 0]),\n",
        "            5: np.array([0, 0]),\n",
        "        }\n",
        "        self._action_to_names = {\n",
        "            0: 'RIGHT',\n",
        "            1: 'DOWN',\n",
        "            2: 'LEFT',\n",
        "            3: 'UP',\n",
        "            4: 'BOMB',\n",
        "            5: 'WAIT',\n",
        "        }\n",
        "\n",
        "\n",
        "        assert render_mode is None or render_mode in self.metadata[\"render_modes\"]\n",
        "        self.render_mode = render_mode\n",
        "\n",
        "        # Define cualquier otro atributo específico de tu entorno\n",
        "        self.window = None\n",
        "        self.clock = None\n",
        "\n",
        "        # Inicializa el estado inicial de tu entorno\n",
        "        #self.state = np.zeros((width, height), dtype=np.float32)\n",
        "\n",
        "    def distance(self, pos1, pos2):\n",
        "        # buscamos la distancia entre el agente y un obstaculo\n",
        "        return np.sqrt((pos1[0] - pos2[0])**2 + (pos1[1] - pos2[1])**2)\n",
        "\n",
        "    def find_closest_obstacle(self, agent_position):\n",
        "        \"\"\"Encuentra la posición del obstáculo más cercano a la posición del agente.\"\"\"\n",
        "        closest_obstacle = None\n",
        "        min_distance = float('inf')  # Inicializar con infinito para asegurar que cualquier distancia sea menor\n",
        "\n",
        "        # Iterar sobre las cajas rompibles e irrompibles para encontrar la más cercana al agente\n",
        "        for box in self.list_boxes + self.list_boxes_breakable:\n",
        "            obstacle_position = box.pos\n",
        "            d = self.distance(agent_position, obstacle_position)\n",
        "            if d < min_distance:\n",
        "                min_distance = d\n",
        "                closest_obstacle = obstacle_position\n",
        "\n",
        "        return closest_obstacle\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def _tile_is_free(self,direction):\n",
        "        movement = self._agent_location + direction\n",
        "        if (exist(self.list_boxes,movement)):\n",
        "            return False\n",
        "        return True\n",
        "\n",
        "    def _get_obs(self):\n",
        "        agent_position = self._agent_location\n",
        "        closest_obstacle = self.find_closest_obstacle(agent_position)\n",
        "        bomb_position = self.bomb.pos if self.active_bomb == 1 else np.array([0, 0])\n",
        "\n",
        "        # Verificar si closest_obstacle no es None antes de aplanarlo\n",
        "        if closest_obstacle is not None:\n",
        "            closest_obstacle = closest_obstacle.flatten()\n",
        "        else:\n",
        "            # Si no hay obstáculo cercano, puedes proporcionar algún valor por defecto\n",
        "            closest_obstacle = np.zeros_like(agent_position)\n",
        "\n",
        "        # Aplana la información en un solo array\n",
        "        flattened_observation = np.concatenate((\n",
        "            agent_position.flatten(),\n",
        "            closest_obstacle.flatten(),\n",
        "            bomb_position.flatten()\n",
        "        ))\n",
        "\n",
        "        return np.array(flattened_observation)\n",
        "\n",
        "    def _get_info(self):\n",
        "        return {\n",
        "            \"distance\": np.linalg.norm(\n",
        "                np.array(self._agent_location) - np.array(self._target_location), ord=1\n",
        "            )\n",
        "        }\n",
        "    def reset(self, seed=None, options=None):\n",
        "        # We need the following line to seed self.np_random\n",
        "        super().reset(seed=seed)\n",
        "\n",
        "        self.list_boxes = [] # lista para las cajas rompibles e irrompibles\n",
        "        self.list_boxes_breakable = [] # lista para las cajas rompibles\n",
        "        self.list_enemies = [] # lista que contendra a los enemigos\n",
        "        self.active_explosion = 0\n",
        "        self.active_bomb = 0\n",
        "        self.player_alive = True\n",
        "        self.bomb = Bomb(np.array([0,0]),0)\n",
        "        self.explosion_radius = []\n",
        "        # generamos las cajas irrompibles\n",
        "        for i in range(self.width):\n",
        "            for j in range(self.height):\n",
        "                if ((i % 2 == 1) and (j % 2 == 1)):\n",
        "                    self.list_boxes.append(Box(np.array([i,j]),False,False,False))\n",
        "\n",
        "        # generamos las cajas rompibles\n",
        "        if not self.rompible_file == '':\n",
        "            rompible_info = []\n",
        "            with open(self.rompible_file, \"r\") as file:\n",
        "                for line in file:\n",
        "                    rompible_info.append(line.strip())\n",
        "            if not rompible_info == []:\n",
        "                if len(rompible_info) == self.boxes:\n",
        "                # Procesa la información y genera cajas irrompibles\n",
        "                    rompible_coordinates = []\n",
        "                    for line in rompible_info:\n",
        "                        x, y = map(int, line.split(\",\"))\n",
        "                        rompible_coordinates.append((x, y))\n",
        "                    for coordinates in rompible_coordinates:\n",
        "                        self.list_boxes.append(Box(np.array(coordinates), True, False,False))\n",
        "                        self.list_boxes_breakable.append(Box(np.array(coordinates), True, False,False))\n",
        "        else:\n",
        "            i=0\n",
        "            while i < self.boxes:\n",
        "                box_pos = np.array([self.np_random.integers(0,self.width-1,dtype=int),self.np_random.integers(0,self.height-1,dtype=int)])\n",
        "                for j in range(len(self.list_boxes)):\n",
        "                    if not (exist(self.list_boxes,box_pos)):\n",
        "                        self.list_boxes.append(Box(box_pos,True,False,False))\n",
        "                        self.list_boxes_breakable.append(Box(box_pos,True,False,False))\n",
        "                        i+=1\n",
        "\n",
        "        '''for i in range(len(self.list_boxes_breakable)):\n",
        "            print(self.list_boxes_breakable[i].pos)'''\n",
        "        # Choose the agent's location uniformly at random\n",
        "        '''aux = True\n",
        "        while (aux):\n",
        "            x = self.np_random.integers(0, self.width, dtype=int)\n",
        "            y = self.np_random.integers(0, self.height, dtype=int)\n",
        "            if not (exist(self.list_boxes,np.array([x,y]))):\n",
        "                aux = False\n",
        "                self._agent_location = np.array([x,y])\n",
        "            '''\n",
        "        self._agent_location = np.array([2,2])\n",
        "\n",
        "        # Choose target location between breakable boxes\n",
        "        target_box = self.list_boxes_breakable[self.np_random.integers(0,len(self.list_boxes_breakable),dtype=int)]\n",
        "        for i in range(len(self.list_boxes)):\n",
        "            if (np.array_equal(target_box.pos,self.list_boxes[i].pos)):\n",
        "                self.list_boxes[i].isTarget = True\n",
        "                self._target_location = target_box.pos\n",
        "                self._target_index = i\n",
        "\n",
        "\n",
        "        # Choose random position for the enemies in horizontal axis\n",
        "        '''if (self.enemies_x > 0):\n",
        "            i = 0\n",
        "            while i < self.enemies_x:\n",
        "                m = self.np_random.integers(0, self.width, dtype=int)\n",
        "                n = self.np_random.integers(0, self.height, dtype=int)\n",
        "                if not (exist(self.list_boxes,np.array([m,n])) or np.array_equal(self._agent_location,np.array([m,n])) or exist(self.list_enemies,np.array([m,n]))):\n",
        "                    w = self.np_random.integers(0, 2, dtype=int) # 0: Up, 1: Down\n",
        "                    self.list_enemies.append(Enemy(np.array([m,n]),0,w,True)) # 0 en orientation es horizontal\n",
        "                    i+=1\n",
        "        # Choose random position for the enemies in vertical axis\n",
        "        if (self.enemies_y > 0):\n",
        "            i = 0\n",
        "            while i < self.enemies_y:\n",
        "                o = self.np_random.integers(0, self.width, dtype=int)\n",
        "                p = self.np_random.integers(0, self.height, dtype=int)\n",
        "                if not (exist(self.list_boxes,np.array([o,p])) or np.array_equal(self._agent_location,np.array([o,p])) or exist(self.list_enemies,np.array([o,p]))):\n",
        "                    w = self.np_random.integers(0, 2, dtype=int) # 0: Left, 1: Right\n",
        "                    self.list_enemies.append(Enemy(np.array([o,p]),1,w,True)) # 1 en orientation es vertical\n",
        "                    i+=1'''\n",
        "        enemigo_fijo = Enemy(np.array([4,4]),0,0,True)\n",
        "        self.list_enemies.append(enemigo_fijo)\n",
        "        observation = self._get_obs()\n",
        "        info = self._get_info()\n",
        "\n",
        "        if self.render_mode == \"human\":\n",
        "            self._render_frame()\n",
        "\n",
        "        return observation, info\n",
        "\n",
        "\n",
        "\n",
        "    def step(self, action):\n",
        "        reward = 0\n",
        "        # Map the action (element of {0,1,2,3}) to the direction we walk in\n",
        "        direction = self._action_to_direction[action]\n",
        "        #print(self._action_to_names[action])\n",
        "        # We use `np.clip` to make sure we don't leave the grid\n",
        "        x,y = self._agent_location + direction\n",
        "        #print(x,y)\n",
        "\n",
        "        #-------------------------------------Bomb Explosion-------------------------------------------#\n",
        "        if (self.active_bomb == 1):\n",
        "            # hay una bomba activa, por lo que se debe verificar si exploto\n",
        "            if (self.bomb.timer == 0):\n",
        "                # calculamos el radio de explosion que es un bloque mas que el radio de la bomba\n",
        "                self.explosion_radius = []\n",
        "                for i in range(4):\n",
        "                    self.explosion_radius.append(Explosion(np.array(self.bomb.pos + self._action_to_direction[i])))\n",
        "                self.explosion_radius.append(Explosion(self.bomb.pos))\n",
        "                self.active_explosion = 1\n",
        "                # verificamos si el agente esta en el radio de explosion\n",
        "                if (exist(self.explosion_radius,self._agent_location)):\n",
        "                    self.player_alive = False\n",
        "                    observation = self._get_obs()\n",
        "                    info = self._get_info()\n",
        "                    reward = -10\n",
        "                    terminated = 0\n",
        "                    return observation, reward, terminated, True, info\n",
        "\n",
        "                # verificamos si las cajas rompibles estan en el radio de explosion\n",
        "                for i in range(len(self.list_boxes)):\n",
        "                    if (self.list_boxes[i].isBreakable):\n",
        "                        if (exist(self.explosion_radius,self.list_boxes[i].pos)):\n",
        "                            self.list_boxes[i].isBroken = True\n",
        "                            reward += 7\n",
        "                            if (self.list_boxes[i].isTarget):\n",
        "                                reward += 20\n",
        "\n",
        "                # verificamos si los enemigos estan en el radio de explosion\n",
        "                for i in range(len(self.list_enemies)):\n",
        "                    if (exist(self.explosion_radius,self.list_enemies[i].pos)):\n",
        "                        self.list_enemies[i].isAlive = False\n",
        "                        # faltaria cambiar la recompenza obtenida por matar un enemigo\n",
        "                        reward += 5\n",
        "                self._render_frame()\n",
        "                self.active_bomb = 0\n",
        "                self.explosion_radius = []\n",
        "            else:\n",
        "                self.bomb.timer -= 1\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        #-------------------------------------Agent movement-------------------------------------------#\n",
        "        if (action == 2 or action == 0) and self._tile_is_free(direction):\n",
        "            self._agent_location = np.clip(\n",
        "                self._agent_location + direction, 0, self.width - 1\n",
        "            )\n",
        "        elif (action == 1 or action == 3) and self._tile_is_free(direction):\n",
        "            self._agent_location = np.clip(\n",
        "                self._agent_location + direction, 0, self.height - 1\n",
        "            )\n",
        "\n",
        "        #-------------------------------------Hit an enemy-------------------------------------------#\n",
        "        for i in range(len(self.list_enemies)):\n",
        "            if self.list_enemies[i].isAlive:\n",
        "                if (np.array_equal(self._agent_location,self.list_enemies[i].pos)):\n",
        "                    self.player_alive = False\n",
        "                    observation = self._get_obs()\n",
        "                    info = self._get_info()\n",
        "                    reward = -10\n",
        "                    terminated = 0\n",
        "                    return observation, reward, terminated, True, info\n",
        "\n",
        "\n",
        "        #-------------------------------------Enemy Movement-------------------------------------------#\n",
        "        for i in range(len(self.list_enemies)):\n",
        "            if (self.list_enemies[i].isAlive): # verificamos que este vivo\n",
        "                # Separamos el movimiento entre vertical y horizontal\n",
        "                if self.list_enemies[i].orientation == 0: #movimiento horizontal\n",
        "                    if self.list_enemies[i].way == 0: #movimiento a la izquierda\n",
        "                        # verificamos que no choque con el limite\n",
        "                        if (self.list_enemies[i].pos[0] == 0) or (exist(self.list_boxes,self.list_enemies[i].pos + self._action_to_direction[2]) or (exist(self.list_enemies,self.list_enemies[i].pos + self._action_to_direction[2]))): # llego al limite de la izquierda, entonces lo cambiamos de sentido\n",
        "                            self.list_enemies[i].way = 1\n",
        "                            if exist(self.list_boxes,self.list_enemies[i].pos + self._action_to_direction[0]):\n",
        "                                self.list_enemies[i].pos = self.list_enemies[i].pos + self._action_to_direction[4] # lo dejamos quieto\n",
        "                            else:\n",
        "                                self.list_enemies[i].pos = self.list_enemies[i].pos + self._action_to_direction[0] #lo movemos a la derecha\n",
        "                        else:\n",
        "                            self.list_enemies[i].pos = self.list_enemies[i].pos + self._action_to_direction[2] # lo movemos a la izquierda\n",
        "\n",
        "                    else: #movimiento a la derecha\n",
        "                        # verificamos que no choque con el limite\n",
        "                        if (self.list_enemies[i].pos[0] == self.width-1) or (exist(self.list_boxes,self.list_enemies[i].pos + self._action_to_direction[0]) or (exist(self.list_enemies,self.list_enemies[i].pos + self._action_to_direction[0]))):\n",
        "                            self.list_enemies[i].way = 0\n",
        "                            if exist(self.list_boxes,self.list_enemies[i].pos + self._action_to_direction[0]):\n",
        "                                self.list_enemies[i].pos = self.list_enemies[i].pos + self._action_to_direction[4] # lo dejamos quieto\n",
        "                            else:\n",
        "                                self.list_enemies[i].pos = self.list_enemies[i].pos + self._action_to_direction[2] # lo movemos a la izquierda\n",
        "                        else:\n",
        "                            self.list_enemies[i].pos = self.list_enemies[i].pos + self._action_to_direction[0] # lo movemos a la derecha\n",
        "\n",
        "\n",
        "                else:\n",
        "                    # movimiento vertical\n",
        "                    if self.list_enemies[i].way == 0: # movimiento hacia arriba\n",
        "                        # se verifica que no choque con nada\n",
        "                        if ((self.list_enemies[i].pos[1] == 0) or (exist(self.list_boxes,self.list_enemies[i].pos + self._action_to_direction[3])) or (exist(self.list_enemies,self.list_enemies[i].pos + self._action_to_direction[3]))):\n",
        "                            self.list_enemies[i].way = 1\n",
        "                            if exist(self.list_boxes,self.list_enemies[i].pos + self._action_to_direction[1]):\n",
        "                                self.list_enemies[i].pos = self.list_enemies[i].pos + self._action_to_direction[4]\n",
        "                            else:\n",
        "                                self.list_enemies[i].pos = self.list_enemies[i].pos + self._action_to_direction[1] # lo movemos hacia abajo\n",
        "                        else:\n",
        "                            self.list_enemies[i].pos = self.list_enemies[i].pos + self._action_to_direction[3] # lo movemos hacia arriba\n",
        "                    else: # movimiento hacia abajo\n",
        "                        # se verifica que no choque con nada\n",
        "                        if ((self.list_enemies[i].pos[1] == self.height-1) or (exist(self.list_boxes,self.list_enemies[i].pos + self._action_to_direction[1])) or (exist(self.list_enemies,self.list_enemies[i].pos + self._action_to_direction[1]))):\n",
        "                            self.list_enemies[i].way = 0\n",
        "                            if exist(self.list_boxes,self.list_enemies[i].pos + self._action_to_direction[3]):\n",
        "                                self.list_enemies[i].pos = self.list_enemies[i].pos + self._action_to_direction[4]\n",
        "                            else:\n",
        "                                self.list_enemies[i].pos = self.list_enemies[i].pos + self._action_to_direction[3] # lo movemos hacia arriba\n",
        "                        else:\n",
        "                            self.list_enemies[i].pos = self.list_enemies[i].pos + self._action_to_direction[1] # lo movemos hacia abajo\n",
        "\n",
        "\n",
        "        #-------------------------------------Bomb Placement-------------------------------------------#\n",
        "        if (action == 4) and (self.active_bomb == 0):\n",
        "            # no hay una bomba activa, por lo que se puede poner una\n",
        "            self.active_bomb = 1\n",
        "            self.bomb = Bomb(self._agent_location,6)\n",
        "            reward = 1\n",
        "            # si el target esta visible, debe dejar de ganar recomensa por colocar bombas\n",
        "            if (self.list_boxes[self._target_index].isBroken):\n",
        "                reward = 0\n",
        "\n",
        "\n",
        "        # An episode is done if the agent has reached the target\n",
        "        terminated = np.array_equal(self._agent_location, self._target_location)\n",
        "        observation = self._get_obs()\n",
        "        info = self._get_info()\n",
        "\n",
        "        if self.render_mode == \"human\":\n",
        "            self._render_frame()\n",
        "        if (np.array_equal(self._agent_location,self._target_location)):\n",
        "            reward = 100\n",
        "            print('                 Ganaste\\n')\n",
        "            terminated = 1\n",
        "            return observation, reward, terminated, True, info\n",
        "\n",
        "        # verificamos si la salida esta expuesta, de estarlo, la recompensa debiese tornarse negativa para que\n",
        "        # agente no rompa todas las cajas antes de salirse\n",
        "        '''if (self.list_boxes[self._target_index].isBroken):\n",
        "            reward = -5'''\n",
        "        return observation, reward, terminated, False, info\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def render(self):\n",
        "        if self.render_mode == \"rgb_array\":\n",
        "            return self._render_frame()\n",
        "\n",
        "    def _render_frame(self):\n",
        "        if self.window is None and self.render_mode == \"human\":\n",
        "            pygame.init()\n",
        "            pygame.display.init()\n",
        "            pygame.display.set_caption(\"Mi Juego Genial\")\n",
        "            self.window = pygame.display.set_mode((self.window_width, self.window_height))\n",
        "        if self.clock is None and self.render_mode == \"human\":\n",
        "            self.clock = pygame.time.Clock()\n",
        "\n",
        "        canvas = pygame.Surface((self.window_width, self.window_height))\n",
        "        canvas.fill((255, 255, 255))\n",
        "        if(self.width > self.height):\n",
        "            pix_square_size = (\n",
        "                self.window_width / self.width\n",
        "        )  # The size of a single grid square in pixels\n",
        "        else:\n",
        "            pix_square_size = (\n",
        "                self.window_height / self.height\n",
        "            )\n",
        "\n",
        "        # ---------------------------Now we draw the agent -------------------------\n",
        "        pygame.draw.circle(\n",
        "            canvas,\n",
        "            (0, 0, 255),\n",
        "            (self._agent_location + 0.5) * pix_square_size,\n",
        "            pix_square_size / 3,\n",
        "        )\n",
        "\n",
        "        # ------------------------------------Now we draw the boxes------------------------------------\n",
        "        for i in range(len(self.list_boxes)):\n",
        "            if (self.list_boxes[i].isBreakable):\n",
        "                if(self.list_boxes[i].isTarget and self.list_boxes[i].isBroken): # target visible\n",
        "                    pygame.draw.rect(\n",
        "                        canvas,\n",
        "                        (52, 118, 32),\n",
        "                        pygame.Rect(\n",
        "                            (self.list_boxes[i].pos * pix_square_size),\n",
        "                            (pix_square_size, pix_square_size),\n",
        "                        ),\n",
        "                    )\n",
        "                elif not (self.list_boxes[i].isBroken): #cajas todavia visibles\n",
        "                    pygame.draw.rect(\n",
        "                    canvas,\n",
        "                    (157, 124, 63),\n",
        "                    pygame.Rect(\n",
        "                        (self.list_boxes[i].pos * pix_square_size),\n",
        "                        (pix_square_size, pix_square_size),\n",
        "                    ),\n",
        "                )\n",
        "            else: # undestructible boxes\n",
        "                pygame.draw.rect(\n",
        "                    canvas,\n",
        "                    (88, 82, 72),\n",
        "                    pygame.Rect(\n",
        "                        (self.list_boxes[i].pos * pix_square_size),\n",
        "                        (pix_square_size, pix_square_size),\n",
        "                    ),\n",
        "                )\n",
        "\n",
        "        # ------------------------------------Now we draw the enemies------------------------------------\n",
        "        for i in range(len(self.list_enemies)):\n",
        "            if self.list_enemies[i].isAlive:\n",
        "                pygame.draw.circle(\n",
        "                canvas,\n",
        "                (184, 22, 37),\n",
        "                (self.list_enemies[i].pos + 0.5) * pix_square_size,\n",
        "                pix_square_size / 3,\n",
        "            )\n",
        "\n",
        "        # ------------------------------------Now we draw the bombs------------------------------------\n",
        "        if (self.active_bomb == 1):\n",
        "            pygame.draw.circle(\n",
        "                canvas,\n",
        "                (0, 0, 0),\n",
        "                (self.bomb.pos + 0.4) * pix_square_size,\n",
        "                pix_square_size / 3,\n",
        "            )\n",
        "\n",
        "        # ------------------------------------Now we draw the explosion------------------------------------\n",
        "        if (self.active_explosion == 1):\n",
        "            for i in range(len(self.explosion_radius)):\n",
        "                pygame.draw.circle(\n",
        "                    canvas,\n",
        "                    (206, 125, 9),\n",
        "                    (self.explosion_radius[i].pos + 0.5) * pix_square_size,\n",
        "                    pix_square_size / 3,\n",
        "                )\n",
        "\n",
        "        # Finally, add some gridlines\n",
        "        for x in range(self.height + 1):\n",
        "            pygame.draw.line(\n",
        "                canvas,\n",
        "                0,\n",
        "                (0, pix_square_size * x),\n",
        "                (self.window_width, pix_square_size * x),\n",
        "                width=3,\n",
        "            )\n",
        "\n",
        "        for y in range(self.width + 1):\n",
        "            pygame.draw.line(\n",
        "                canvas,\n",
        "                0,\n",
        "                (pix_square_size * y, 0),\n",
        "                (pix_square_size * y, self.window_height),\n",
        "                width=3,\n",
        "            )\n",
        "\n",
        "        if self.render_mode == \"human\":\n",
        "            # The following line copies our drawings from `canvas` to the visible window\n",
        "            self.window.blit(canvas, canvas.get_rect())\n",
        "            pygame.event.pump()\n",
        "            pygame.display.update()\n",
        "\n",
        "            # We need to ensure that human-rendering occurs at the predefined framerate.\n",
        "            # The following line will automatically add a delay to keep the framerate stable.\n",
        "            self.clock.tick(self.metadata[\"render_fps\"])\n",
        "        else:  # rgb_array\n",
        "            return np.transpose(\n",
        "                np.array(pygame.surfarray.pixels3d(canvas)), axes=(1, 0, 2)\n",
        "            )\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VSXImBTgayXc"
      },
      "source": [
        "ReplayBuffer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "6Hr1idWBa08N"
      },
      "outputs": [],
      "source": [
        "from collections import deque\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class ReplayBuffer:\n",
        "    def __init__(self, max_capacity):\n",
        "        self.max_capacity = max_capacity\n",
        "\n",
        "        # deques, uno por cada elemento\n",
        "        self.states = deque(maxlen=max_capacity)\n",
        "        self.actions = deque(maxlen=max_capacity)\n",
        "        self.rewards = deque(maxlen=max_capacity)\n",
        "        self.next_states = deque(maxlen=max_capacity)\n",
        "        self.dones = deque(maxlen=max_capacity)\n",
        "\n",
        "    def append(self, state, action, reward, next_state, done):\n",
        "        # Almacenar una transicion\n",
        "        self.states.append(state)\n",
        "        self.actions.append(action)\n",
        "        self.rewards.append(reward)\n",
        "        self.next_states.append(next_state)\n",
        "        self.dones.append(done)\n",
        "\n",
        "    def sample(self, batch_size):\n",
        "        if len(self.states) < 2 * batch_size:\n",
        "            return []\n",
        "\n",
        "        indices = sorted(np.random.choice(np.arange(len(self.states)), batch_size, replace=False))\n",
        "\n",
        "        return [\n",
        "            np.stack([np.array(self.states[i]) for i in indices]),\n",
        "            np.stack([np.array(self.actions[i]) for i in indices]),\n",
        "            np.stack([np.array(self.rewards[i]) for i in indices]),\n",
        "            np.stack([np.array(self.next_states[i]) for i in indices]),\n",
        "            np.stack([np.array(self.dones[i]) for i in indices])\n",
        "        ]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XvhEMAAzaQJy"
      },
      "source": [
        "DQNAgent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "I_SGwCBcasuv"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "rng = np.random.default_rng()\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from IPython.display import clear_output\n",
        "from collections import deque\n",
        "import tensorflow as tf\n",
        "import logging\n",
        "\n",
        "\n",
        "class DQNAgent:\n",
        "\n",
        "    def __init__(self, env, learning_rate, epsilon, epsilon_decay, gamma, batch_size, target_update_period, training_update_period, buffer_limit):\n",
        "        self.env = env\n",
        "\n",
        "        self.learning_rate = learning_rate\n",
        "        self.epsilon = epsilon\n",
        "        self.epsilon_decay = epsilon_decay\n",
        "        self.gamma = gamma\n",
        "        self.batch_size = batch_size\n",
        "        self.target_update_period = target_update_period\n",
        "        self.training_update_period = training_update_period\n",
        "\n",
        "        # Create the Q-network and the target network\n",
        "        tf.keras.backend.clear_session() # start by deleting all existing models to be gentle on the RAM\n",
        "        self.model = self.build_model(self.learning_rate)\n",
        "        self.target_model = self.build_model(self.learning_rate)\n",
        "        self.target_model.set_weights(self.model.get_weights())\n",
        "\n",
        "        # Create the replay memory\n",
        "        self.buffer = ReplayBuffer(buffer_limit)\n",
        "\n",
        "    def build_model(self, learning_rate):\n",
        "        model = tf.keras.Sequential()\n",
        "        model.add(tf.keras.layers.Dense(64, input_shape=(self.env.observation_space.shape[0],), activation='relu'))\n",
        "        model.add(tf.keras.layers.Dense(self.env.action_space.n, activation='linear'))  # Utiliza env.action_space.n\n",
        "\n",
        "        # Compila el modelo con el optimizador y la función de pérdida apropiados\n",
        "        model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate), loss='mse')\n",
        "\n",
        "        return model\n",
        "\n",
        "    def act(self, state):\n",
        "\n",
        "        # epsilon-greedy\n",
        "        if np.random.rand() < self.epsilon: # Random selection\n",
        "            action = self.env.action_space.sample()\n",
        "        else: # Use the Q-network to get the greedy action\n",
        "            action = self.model.predict(state.reshape((1, self.env.observation_space.shape[0])), verbose=0)[0].argmax()\n",
        "\n",
        "        # Decay epsilon\n",
        "        self.epsilon *= 1 - self.epsilon_decay\n",
        "        self.epsilon = max(0.05, self.epsilon)\n",
        "\n",
        "        return action\n",
        "\n",
        "    def update(self, batch):\n",
        "\n",
        "        # Get the minibatch\n",
        "        states, actions, rewards, next_states, dones = batch\n",
        "\n",
        "        # Predict the Q-values in the current state\n",
        "        targets = np.array(self.model.predict_on_batch(states))\n",
        "\n",
        "        # Predict the Q-values in the next state using the target model\n",
        "        next_Q_value = np.array(self.target_model.predict_on_batch(next_states)).max(axis=1)\n",
        "\n",
        "        # Terminal states have a value of 0\n",
        "        next_Q_value[dones] = 0.0\n",
        "\n",
        "        # Compute the target\n",
        "        for i in range(self.batch_size):\n",
        "            targets[i, actions[i]] = rewards[i] + self.gamma * next_Q_value[i]\n",
        "\n",
        "        # Train the model on the minibatch\n",
        "        history = self.model.fit(states, targets, epochs=1, batch_size=self.batch_size, verbose=0)\n",
        "\n",
        "        return history.history['loss'][0]\n",
        "\n",
        "    def train(self, nb_episodes):\n",
        "\n",
        "        steps = 0\n",
        "        returns = []\n",
        "        losses = []\n",
        "\n",
        "        for episode in range(nb_episodes):\n",
        "\n",
        "            # Reset\n",
        "            state, info = self.env.reset()\n",
        "            done = False\n",
        "            steps_episode = 0\n",
        "            return_episode = 0\n",
        "\n",
        "            loss_episode = []\n",
        "\n",
        "            # Sample the episode\n",
        "            while not done:\n",
        "\n",
        "                # Select an action\n",
        "                action = self.act(state)\n",
        "\n",
        "                # Perform the action\n",
        "                next_state, reward, terminal, truncated, info = self.env.step(action)\n",
        "\n",
        "                # End of the episode\n",
        "                done = terminal or truncated\n",
        "\n",
        "                # Store the transition\n",
        "                self.buffer.append(state, action, reward, next_state, done)\n",
        "\n",
        "                # Sample a minibatch\n",
        "                batch = self.buffer.sample(self.batch_size)\n",
        "\n",
        "                # Train the NN on the minibatch\n",
        "                if len(batch) > 0 and steps % self.training_update_period == 0:\n",
        "                    loss = self.update(batch)\n",
        "                    loss_episode.append(loss)\n",
        "\n",
        "                # Update the target model\n",
        "                if steps > self.target_update_period and steps % self.target_update_period == 0:\n",
        "                    self.target_model.set_weights(self.model.get_weights())\n",
        "\n",
        "                # Go in the next state\n",
        "                state = next_state\n",
        "\n",
        "                # Increment time\n",
        "                steps += 1\n",
        "                steps_episode += 1\n",
        "                return_episode += reward\n",
        "\n",
        "                if done:\n",
        "                    break\n",
        "\n",
        "            # Store info\n",
        "            returns.append(return_episode)\n",
        "            losses.append(np.mean(loss_episode))\n",
        "\n",
        "            # Print info\n",
        "            clear_output(wait=True)\n",
        "            print('Episode', episode+1)\n",
        "            print(' total steps:', steps)\n",
        "            print(' length of the episode:', steps_episode)\n",
        "            print(' return of the episode:', return_episode)\n",
        "            print(' current loss:', np.mean(loss_episode))\n",
        "            print(' epsilon:', self.epsilon)\n",
        "\n",
        "        return returns, losses\n",
        "\n",
        "    def test(self):\n",
        "\n",
        "        old_epsilon = self.epsilon\n",
        "        self.epsilon = 0.0\n",
        "\n",
        "        state, info = self.env.reset()\n",
        "        nb_steps = 0\n",
        "        done = False\n",
        "\n",
        "        while not done:\n",
        "            action = self.act(state)\n",
        "            next_state, reward, terminal, truncated, info = self.env.step(action)\n",
        "            done = terminal or truncated\n",
        "            state = next_state\n",
        "            nb_steps += 1\n",
        "\n",
        "        self.epsilon = old_epsilon\n",
        "        return nb_steps"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7WvQ3QC4bfH7"
      },
      "source": [
        "Main"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "id": "OPXf1chsbw1M",
        "outputId": "5fa1495c-51d6-4ede-936b-2c3d779d2b9e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Box(0.0, 1.0, (6,), float32)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-1ee5e3a1588d>\u001b[0m in \u001b[0;36m<cell line: 33>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;31m# Train the agent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m \u001b[0mreturns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnb_episodes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;31m# Plot the returns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-37-d10a0bb3102b>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, nb_episodes)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m             \u001b[0;31m# Reset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m             \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m             \u001b[0mdone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m             \u001b[0msteps_episode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-35-037afceaf2ff>\u001b[0m in \u001b[0;36mreset\u001b[0;34m(self, seed, options)\u001b[0m\n\u001b[1;32m    202\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrompible_file\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m             \u001b[0mrompible_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m             \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrompible_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m                     \u001b[0mrompible_info\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Lab3/cajas.txt'"
          ]
        }
      ],
      "source": [
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def running_average(x, N):\n",
        "    kernel = np.ones(N) / N\n",
        "    return np.convolve(x, kernel, mode='same')\n",
        "\n",
        "# Parameters\n",
        "nb_episodes = 150\n",
        "batch_size = 32\n",
        "\n",
        "epsilon = 1.0\n",
        "epsilon_decay = 0.0005\n",
        "\n",
        "gamma = 0.99\n",
        "\n",
        "learning_rate = 0.005\n",
        "buffer_limit = 5000\n",
        "target_update_period = 100\n",
        "training_update_period = 4\n",
        "\n",
        "file_str = 'Lab3/cajas.txt'\n",
        "\n",
        "# Create the environment\n",
        "env = BombermanEnv(5,5,1,0,1,file_str,'human')\n",
        "print(env.observation_space)\n",
        "\n",
        "# Create the agent\n",
        "agent = DQNAgent(env, learning_rate, epsilon, epsilon_decay, gamma, batch_size, target_update_period, training_update_period, buffer_limit)\n",
        "\n",
        "# Train the agent\n",
        "returns, losses = agent.train(nb_episodes)\n",
        "\n",
        "# Plot the returns\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(returns)\n",
        "plt.plot(running_average(returns, 10))\n",
        "plt.xlabel(\"Episodes\")\n",
        "plt.ylabel(\"Returns\")\n",
        "\n",
        "# Plot the losses\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(losses)\n",
        "plt.xlabel(\"Episodes\")\n",
        "plt.ylabel(\"Training loss\")\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}